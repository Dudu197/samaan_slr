{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8368cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.models import resnet18\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7f647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"../dataset_output/google_asl/imgs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e610bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d2a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7056c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e23f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32*3\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fe95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6cde8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dudu/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "resnet = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e795ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = resnet.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e1d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(os.listdir(dataset_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a2af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the fully connected layer to match the number of classes\n",
    "resnet.fc = nn.Linear(num_ftrs, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb189a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=10e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21ef0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=250, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86985a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09ec3864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4.6324, Accuracy: 0.1907\n",
      "2024-03-15 20:49:28.568292\n",
      "==========\n",
      "Epoch 2/10, Loss: 3.0534, Accuracy: 0.3044\n",
      "2024-03-15 20:55:22.617669\n",
      "==========\n",
      "Epoch 3/10, Loss: 2.5797, Accuracy: 0.2786\n",
      "2024-03-15 21:01:08.162866\n",
      "==========\n",
      "Epoch 4/10, Loss: 2.2900, Accuracy: 0.4032\n",
      "2024-03-15 21:06:56.829164\n",
      "==========\n",
      "Epoch 5/10, Loss: 2.0609, Accuracy: 0.4410\n",
      "2024-03-15 21:12:39.262165\n",
      "==========\n",
      "Epoch 6/10, Loss: 1.8627, Accuracy: 0.4564\n",
      "2024-03-15 21:18:23.193559\n",
      "==========\n",
      "Epoch 7/10, Loss: 1.6704, Accuracy: 0.4841\n",
      "2024-03-15 21:24:12.173671\n",
      "==========\n",
      "Epoch 8/10, Loss: 1.4783, Accuracy: 0.4841\n",
      "2024-03-15 21:29:58.287088\n",
      "==========\n",
      "Epoch 9/10, Loss: 1.2719, Accuracy: 0.4699\n",
      "2024-03-15 21:35:41.256108\n",
      "==========\n",
      "Epoch 10/10, Loss: 1.0520, Accuracy: 0.4802\n",
      "2024-03-15 21:41:21.491280\n",
      "==========\n",
      "Epoch 11/10, Loss: 0.8411, Accuracy: 0.4039\n",
      "2024-03-15 21:46:57.250673\n",
      "==========\n",
      "Epoch 12/10, Loss: 0.6589, Accuracy: 0.4468\n",
      "2024-03-15 21:52:37.095159\n",
      "==========\n",
      "Epoch 13/10, Loss: 0.5138, Accuracy: 0.4779\n",
      "2024-03-15 21:58:19.823711\n",
      "==========\n",
      "Epoch 14/10, Loss: 0.4178, Accuracy: 0.4624\n",
      "2024-03-15 22:04:01.296515\n",
      "==========\n",
      "Epoch 15/10, Loss: 0.3455, Accuracy: 0.4747\n",
      "2024-03-15 22:09:47.890060\n",
      "==========\n",
      "Epoch 16/10, Loss: 0.2975, Accuracy: 0.4783\n",
      "2024-03-15 22:15:27.951108\n",
      "==========\n",
      "Epoch 17/10, Loss: 0.2769, Accuracy: 0.3484\n",
      "2024-03-15 22:21:03.543345\n",
      "==========\n",
      "Epoch 18/10, Loss: 0.2330, Accuracy: 0.4662\n",
      "2024-03-15 22:26:42.183222\n",
      "==========\n",
      "Epoch 19/10, Loss: 0.2170, Accuracy: 0.4665\n",
      "2024-03-15 22:32:24.187930\n",
      "==========\n",
      "Epoch 20/10, Loss: 0.2014, Accuracy: 0.4704\n",
      "2024-03-15 22:38:08.822539\n",
      "==========\n",
      "Epoch 21/10, Loss: 0.1764, Accuracy: 0.4752\n",
      "2024-03-15 22:43:52.585091\n",
      "==========\n",
      "Epoch 22/10, Loss: 0.1854, Accuracy: 0.4672\n",
      "2024-03-15 22:49:34.402213\n",
      "==========\n",
      "Epoch 23/10, Loss: 0.1650, Accuracy: 0.4676\n",
      "2024-03-15 22:55:20.056376\n",
      "==========\n",
      "Epoch 24/10, Loss: 0.1411, Accuracy: 0.4602\n",
      "2024-03-15 23:01:05.109650\n",
      "==========\n",
      "Epoch 25/10, Loss: 0.1407, Accuracy: 0.4563\n",
      "2024-03-15 23:06:43.154731\n",
      "==========\n",
      "Epoch 26/10, Loss: 0.1445, Accuracy: 0.4714\n",
      "2024-03-15 23:12:26.772286\n",
      "==========\n",
      "Epoch 27/10, Loss: 0.1260, Accuracy: 0.4726\n",
      "2024-03-15 23:18:04.046838\n",
      "==========\n",
      "Epoch 28/10, Loss: 0.1280, Accuracy: 0.4696\n",
      "2024-03-15 23:23:34.668789\n",
      "==========\n",
      "Epoch 29/10, Loss: 0.1222, Accuracy: 0.4651\n",
      "2024-03-15 23:29:20.870921\n",
      "==========\n",
      "Epoch 30/10, Loss: 0.1194, Accuracy: 0.4641\n",
      "2024-03-15 23:35:10.872646\n",
      "==========\n",
      "Epoch 31/10, Loss: 0.1069, Accuracy: 0.4568\n",
      "2024-03-15 23:41:01.489117\n",
      "==========\n",
      "Epoch 32/10, Loss: 0.1070, Accuracy: 0.4679\n",
      "2024-03-15 23:46:38.297068\n",
      "==========\n",
      "Epoch 33/10, Loss: 0.1060, Accuracy: 0.4646\n",
      "2024-03-15 23:52:24.429642\n",
      "==========\n",
      "Epoch 34/10, Loss: 0.0960, Accuracy: 0.4664\n",
      "2024-03-15 23:58:00.312656\n",
      "==========\n",
      "Epoch 35/10, Loss: 0.0997, Accuracy: 0.4733\n",
      "2024-03-16 00:03:36.367892\n",
      "==========\n",
      "Epoch 36/10, Loss: 0.0920, Accuracy: 0.4719\n",
      "2024-03-16 00:09:15.917579\n",
      "==========\n",
      "Epoch 37/10, Loss: 0.0917, Accuracy: 0.4714\n",
      "2024-03-16 00:15:00.455976\n",
      "==========\n",
      "Epoch 38/10, Loss: 0.0915, Accuracy: 0.4512\n",
      "2024-03-16 00:20:45.175173\n",
      "==========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m resnet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      5\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/datasets/folder.py:229\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/datasets/folder.py:268\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/datasets/folder.py:248\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    247\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    resnet.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{10}, Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(str(datetime.now()))\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d88487be",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for _ in range(70))\n",
    "class_total = list(0. for _ in range(70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5460faef",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels)):\n\u001b[1;32m     11\u001b[0m     label \u001b[38;5;241m=\u001b[39m labels[i]\n\u001b[0;32m---> 12\u001b[0m     class_correct[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     13\u001b[0m     class_total[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = resnet(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d9b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.5817\n"
     ]
    }
   ],
   "source": [
    "accuracy = correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00475aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cb8794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2d32194c0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([4.2326, 3.7369, 2.9993, 2.4818, 2.1854, 1.9872, 1.8258, 1.7005, 1.5889, 1.4807, 1.3908, 1.3024, 1.2225, 1.1362, 1.0428, 0.9636, 0.8941, 0.8078, 0.7250, 0.6574, 0.5991, 0.5212, 0.4890, 0.4144, 0.4048, 0.3487, 0.3360, 0.2818, 0.2639, 0.2869, 0.2111, 0.2483, 0.2290, 0.1980, 0.1731, 0.1912, 0.1883, 0.1818, 0.1486, 0.1645, 0.1201, 0.1481, 0.1360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6674ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
